## Introduction

<p> The company under study has a marketing department that has been tracking fourteen different variables on clients who purchased their new life insurance product. The main objective is to determine if the data collected can be effectively used to predict the likelihood that a new customer will buy an insurance product. This issue is significant for the organization since it may help them refine their marketing efforts and more effectively target potential clients. The data set provided contains a response variable that indicates whether a customer has purchased a life insurance product, and this type of data is well suited for supervised learning machine learning algorithms, which can use labelled data to train a model that can predict the purchasing behaviour of new customers. </p>

## Data cleaning and pre-processing

<p> The data cleaning process started by identifying missing values in the dataset. The 'education' column had only 1.85% missing values, so mode imputation was applied. However, the 'marriage' and 'house_owner' variables had more significant shares of missing values, with 35% and 9% missing values, respectively, therefore, to avoid inaccuracy in imputation, missing values were replaced with a new category called 'Unknown'. The approach to missing value treatment ensured that all 40000 observations were preserved in the dataset without any loss, and by doing so the response variable class balance was maintained at initial 50/50 proportion. </p>
<p> Next, typos present in the 'child' variable were identified and fixed. The '0' category was allegedly associated with not having kids ('N' category), so the '0' values were replaced with 'N.' </p>
<p> For encoding categorical variables, integer encoding was used for variables that have natural ordering in them. In cases where missing values were present, they were coded as 0 with the creation of a separate binary variable indicating missing information. One-hot encoding was used for categorical variables with three or more categories, and dummy encoding for variables with only two categories. </p>
<p> Feature engineering was performed by creating two new features. The first feature involved binning the continuous 'house_val' variable into discrete categories (none, low, below median, above median, and high) using percentiles as cut-off points, which addressed the significant number of outliers in the data. The grouping was done inside each ‘region’ to account for differences in house prices across different geographies. The second feature was 'income to house value ratio,' which was calculated by dividing the family income bracket by the binned house value variable. The feature helped to identify customers that likely have more disposable income. </p>

## Modelling methodology

<p> After cleaning the data, the next step is to build classification algorithms to predict the response variable. The first algorithm implemented was <b>Logistic Regression</b>. <b>Recursive Feature Elimination with Cross-Validation (RFECV)</b> was used to select a subset of features with <b>StratifiedKFold cross-validation</b> to ensure that the class distribution was balanced in each fold. However, since RFECV does not consider statistical significance of predictors, so backward stepwise variable selection was performed after to remove statistically insignificant variables from the set of variables generated by it. The remaining subset of variables was then used to predict the response variable in the entire dataset by using 10-fold cross-validation. </p>
<p>Next, tree-based algorithms such as <b>Decision Tree</b>, <b>Random Forest</b>, and <b>Gradient Boosting</b> were implemented. <b>GridSearchCV</b> approach within ‘sklearn’ library was used to perform hyperparameter optimization. For Decision Tree, the function to measure the quality of a split, maximum depth of the decision tree, and the minimum number of samples required to split an internal node were optimized. For Random Forest, the number of trees, the function to measure the quality of a split, maximum depth of each decision tree, and the number of features to consider during each split were optimized. For Gradient Boosting, the same set of parameters as Random Forest were optimized, plus the learning rate, which is a step size used to update the weights.</p>
<p>After optimization, the sets with best parameters were used to run the models and predict the response variables using cross-validation in the similar manner. After applying the Random Forest algorithm, the feature importance scores were extracted to identify the most influential predictors in determining the likelihood of a client purchasing life insurance. This information can be used to gain insight into which variables are the most important in the prediction model and to potentially inform future data collection strategies.</p>
<p>Additionally, <b>Naive Bayes</b> and <b>k-Nearest Neighbours</b> classifiers were attempted as well to compare their performance to the other algorithms and ensure no additional predictive performance could be gained. The performance of each proposed algorithm was assessed using ROC curve with AUC values, accuracy, precision, recall, and F1 scores.</p>

## Results and discussion

<p>During the analysis, visualizations of the data were generated for preliminary exploratory analysis, revealing the following observations. Firstly, the graph suggested that house prices differ across geographic regions, which was further confirmed by a <b>one-way ANOVA test for means</b>. Additionally, the house prices had numerous outliers and a significantly skewed distribution, which indicates that an engineered variable could be useful in predicting the response variable. The violin plots for the mortgage and binned house value variables demonstrated that the distribution for non-subscribers was different, with more non-subscribers belonging to the first mortgage bracket and tend to be having lesser house values. This suggests that these variables could also be valuable for separating the classes. Moreover, by observing the bar plots for categorical variables, it was evident that the gender distribution differed between the two classes, indicating that gender was likely a significant predictor.</p>
<p>The feature importance scores derived from the random forest model confirm that variables created during the feature engineering process are valuable for the analysis. These variables are among the top 5 most important features. Moreover, the mortgage variable is the 6th most important variable, and gender is the 11th most important variable. This confirms the earlier preliminary observations based on the graphs and suggests that these variables are significant for predicting the probability of insurance subscription.</p>

| Algorithm          | TN    | TP    | FN    | FP    | AUC   | Accuracy | Precision | Recall | F1   |
|-------------------|-------|-------|-------|-------|-------|----------|-----------|--------|------|
| Logistic Regression| 13647 | 13614 | 6353  | 6386  | 0.748 | 0.68     | 0.68      | 0.68   | 0.68 |
| Decision Tree      | 13987 | 13198 | 6013  | 6802  | 0.743 | 0.68     | 0.68      | 0.66   | 0.67 |
| Random Forest      | 13457 | 13902 | 6543  | 6098  | 0.749 | 0.68     | 0.68      | 0.69   | 0.69 |
| Gradient Boosting  | 14079 | 13758 | 5921  | 6242  | 0.764 | 0.70     | 0.70      | 0.68   | 0.69 |
| Naïve Bayes        | 14100 | 12461 | 5900  | 7539  | 0.720 | 0.66     | 0.67      | 0.62   | 0.65 |
| k-NN               | 14017 | 13389 | 5983  | 6611  | 0.752 | 0.69     | 0.69      | 0.66   | 0.68 |

<p> Logistic regression, random forest, and k-Nearest Neighbours classifiers achieved similar AUC scores ranging from 0.748 to 0.752, while decision tree and Naive Bayes performed slightly worse with AUCs of 0.743 and 0.720, respectively. Gradient boosting had the highest AUC of 0.764, indicating that it performed the best in terms of correctly classifying positive and negative instances.</br> However, it's important to consider other performance metrics besides AUC. Accuracy and precision indicate the overall correctness of the classifier's predictions, while recall and F1 score provide additional insight into how well the classifier is identifying positive instances. All the six classifiers demonstrate similar performance in terms of accuracy and precision, with values ranging between 0.66 and 0.70. However, the recall and F1 scores show some variation among the models. Gradient Boosting and Random Forest classifiers performed the best in terms of recall and F1 scores, indicating that they have better ability to identify positive instances. Naive Bayes, on the other hand, has the lowest recall and F1 scores, indicating that it struggles to correctly identify positive instances. Overall, Gradient Boosting appears to be the best performing classifier based on its highest AUC, precision recall and F1 scores. </p>

## Conclusions

<p> While the current analysis demonstrates a certain predictive power of supervised machine learning algorithms, there is still room for improvement. Among the six classifiers implemented, Gradient Boosting achieved the highest AUC score of 0.764 and performed the best in terms of correctly classifying positive and negative instances. However, the AUC score still suggests that the collected data cannot be effectively used to predict the likelihood that a new customer will buy an insurance product. This implies that the current data collection process may not be comprehensive enough to capture all relevant factors that influence a customer's decision to purchase a life insurance product. To overcome this limitation, the marketing department may need to rethink the data collection process by generating more features and collecting more observations to have a bigger training sample. Another potential area of improvement for this analysis is to explore more complex algorithms, such as neural networks. Numerous predictive data analytics tasks, including classification problems, have yielded promising results using neural networks. However, they typically perform best when there are many dimensions in the data, which is not the case for the currently available data. As such, it also confirms that it may be beneficial to collect data on more features to enable the use of more complex algorithms. </p>